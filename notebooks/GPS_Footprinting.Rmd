---
title: "GPS Footprinting"
output: html_notebook
---

This is the *GPS Footprinting project*. It is inspired by [Finn et al. Nat Neuro  (2015)](https://www.nature.com/articles/nn.4135) and [Kaufmann et al. Nat Neuro (2015)](https://www.nature.com/articles/s41593-019-0471-7).

GPS data preprocessing performed according to [Ian Barnett's imputation algorithm](https://github.com/ianjamesbarnett/SmartphoneSensorPipeline), originally published in [Biostatistics (2020)](https://academic.oup.com/biostatistics/article-abstract/21/2/e98/5145908).

### Load Required Packages 
```{r load_lib, message=FALSE}
require(ggplot2)
require(summarytools)
require(cowplot)
require(caret)
require(corrplot)
require(RColorBrewer)
source('~/Documents/GitHub/SmartphoneSensorPipeline/Extra/plotting_functions.R')
```

### Setup the paths 
```{r def_paths}
project_path = "~/Documents/xia_gps/"
data_path = file.path(project_path,"beiwe_output_043020")

gps_df_path = file.path(data_path,"Processed_Data/Group/feature_matrix.txt")
```

### Read in data
```{r read_gps}
gps_df = read.table(gps_df_path,header = T, dec = ",", )[,c(1,2,97:111)]

#Define the column types
gps_df$Date = as.Date(gps_df$Date)
gps_df[,3:dim(gps_df)[2]] = apply(gps_df[,3:dim(gps_df)[2]], 2, function(x) as.numeric(x))
head(gps_df)

```

The current data has `r length(unique(gps_df$IID))` subjects, consisting of `r dim(gps_df)[1]` total days, and `r length(colnames(gps_df))-2` GPS features.




```{r fig.width=10, fig.height=4, echo=FALSE}
minMiss_histplot(gps_df,200, "All Data")
```





### Exclude Data
#### 1.  remove 1st and last days
```{r 1st_last_days}
# loop through each subj to remove 1st and last days of gps data
gps_df_clean = data.frame() #initiate a df
for (subj in unique(gps_df$IID)){ #loop through each subj
  gps_df_subj <- subset(gps_df, IID == subj) #get gps_df per subject
  gps_df_subj <- gps_df_subj[2:(dim(gps_df_subj)[1]-1),] #remove the 1st and last days
  gps_df_clean <- rbind(gps_df_clean,gps_df_subj) #combine all subjs
}
```

This step removed `r dim(gps_df)[1] - dim(gps_df_clean)[1]` days. Now, dataset has `r length(unique(gps_df_clean$IID))` subjects, consisting of `r dim(gps_df_clean)[1]` total days, and `r length(colnames(gps_df_clean))-2` GPS features.

```{r fig.width=10, fig.height=4, echo=FALSE}
minMiss_histplot(gps_df_clean,200, "After Removing 1st and Last Days")
```

#### 2.  remove days at the sensitivity threshold
```{r results='asis'}
sensitivity_cutoff = 1440 # this controls the cutoff threshold
gps_df_clean2 = subset(gps_df_clean, MinsMissing < sensitivity_cutoff)
```

This step removed `r dim(gps_df_clean)[1] - dim(gps_df_clean2)[1]` days. Now, dataset has `r length(unique(gps_df_clean2$IID))` subjects, consisting of `r dim(gps_df_clean2)[1]` total days, and `r length(colnames(gps_df_clean2))-2` GPS features.

```{r fig.width=10, fig.height=4, echo=FALSE}
minMiss_histplot(gps_df_clean2,200, paste("After Removing Missing Greater than ",sensitivity_cutoff))
```

```{r fig.width=10, fig.height=4, echo=FALSE}
minMiss_histplot(subset(gps_df_clean2,MinsMissing>=1296),200, "Zoom In Plot")
```

#### 4. Randomly Select Half of Days for Each Subject
```{r}
set.seed(510)
subj_seq = list()
part_times = 10
for (subj in unique(gps_df_clean2$IID)){
  subj_data = subset(gps_df_clean2, IID==subj)
  subj_seq[[subj]] <-createDataPartition(subj_data$IID,times = part_times, p =0.5)
}
```

### 5. Build Correlation Matrix
```{r example_cor_fig, fig.width=3, fig.width=3, fig.align="center"}
# an example of subj 1, and first half
cormat = cor(gps_df_clean2[subj_seq$`14w5qlo8`$Resample01,3:17])
gps_cor = rquery.cormat(cormat, type = "full")
```

```{r create feature matrix for everyone, warning=FALSE}
make_feature_matrix = function(gps_df) {
  subj_mat_1 = list()
  subj_mat_2 = list()
  for (subj in unique(gps_df$IID)){
    subj_data = subset(gps_df_clean2, IID==subj)
    subj_mat_1[[subj]] = lapply(subj_seq[[subj]], function(list) rquery.cormat(subj_data[list,3:17], type = "flatten", graph = F)$r)
    subj_mat_2[[subj]] = lapply(subj_seq[[subj]], function(list) rquery.cormat(subj_data[-list,3:17], type = "flatten", graph = F)$r)
  }
  return(list(subj_mat_1 = subj_mat_1, subj_mat_2 = subj_mat_2 ))
}

gps_clean2_feature = make_feature_matrix(gps_df_clean2)
```
#### 6. Match Target to Database

```{r calc match cor}
# creating a "database" against which target is to be matched with
subj_mat_1 = gps_clean2_feature$subj_mat_1
subj_mat_2 = gps_clean2_feature$subj_mat_2

calc_match_cor = function(subj_mat_1,subj_mat_2) {
  database = list() 
  for (time in 1:part_times) {
      database[[time]] = lapply(subj_mat_2, function(subjmat) subjmat[[time]]$cor)
  }
  
    # match target to database
    match_cor = list()
    for (subj1 in names(subj_mat_1)){ #loop through each subj
      # create a list of target across partitions
      target_list = lapply(subj_mat_1[[subj1]], function(part) part$cor)
      # create a match list
      for (time in 1:part_times){
        target_subj_time = target_list[[time]] #loop through each partition
        for (subj2 in names(subj_mat_2)){ #loop everyone in 2nd half
          data_subj_time = subj_mat_2[[subj2]][[time]]$cor
          match_cor[[subj1]][[as.character(time)]][[subj2]] = cor(target_subj_time,data_subj_time,use = "na.or.complete")
        }
      }
    }
  return(match_cor)
}

match_cor = calc_match_cor(subj_mat_1,subj_mat_2)

```

```{r calc accuracy by partition}
calc_acc_time=function(match_cor) {
  acc_time = array()
  for (time in 1:part_times){
    acc_time[time] = 0
    for (subj in names(subj_mat_1)){
      max_position = which.max(unlist(match_cor[[subj]][[as.character(time)]]))
      predicted_subj = names(subj_mat_1)[max_position]
      if (predicted_subj == subj) {
        acc_time[time] = acc_time[time] + 1
      }
    }
  }
  acc_time = acc_time/length(names(subj_mat_1))
  return(acc_time)
}
acc_time = calc_acc_time(match_cor)
```

```{r plot accuracy by partition histogram }
print(hist(acc_time))
```


```{r calc accuracy by subj}
calc_acc_subj = function(match_cor){
  acc_subj = array()
  for (subj in names(subj_mat_1)){
    acc_subj[subj] = 0
    for (time in 1:part_times){
      max_position = which.max(unlist(match_cor[[subj]][[as.character(time)]]))
      predicted_subj = names(subj_mat_1)[max_position]
      if (predicted_subj == subj) {
        acc_subj[subj] = acc_subj[subj] + 1
      }
    }
  }
  acc_subj_ave = acc_subj/part_times
  return(acc_subj_ave)
}
acc_subj_ave = calc_acc_subj(match_cor)
```

```{r plot accuracy by subjects}
print(plot(acc_subj))
```


#### 7. Permutation Test
```{r warning=FALSE}
gps_df_perm = gps_df_clean2
perm_time = 1000
perm_acc_time = list()
perm_acc_subj = list()
for (i in 1:perm_time) {
  print(paste("processing ...", i,"..."))
  gps_df_perm$IID = sample(gps_df_perm$IID)
  perm_gps = make_feature_matrix(gps_df_perm)
  perm_mat_1 = perm_gps$subj_mat_1
  perm_mat_2 = perm_gps$subj_mat_2
  perm_match_cor = calc_match_cor(perm_mat_1,perm_mat_2)
  perm_acc_time[[i]] = calc_acc_time(perm_match_cor)
  perm_acc_subj[[i]] = calc_acc_subj(perm_match_cor)
}


```

